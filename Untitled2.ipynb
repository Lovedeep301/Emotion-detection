{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86841f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 7480\n",
      "['anger', 'disgust', 'fear', 'guilt', 'joy', 'sadness', 'shame']\n",
      "joy       (1. 0. 0. 0. 0. 0. 0.)  1084\n",
      "anger     (0. 0. 1. 0. 0. 0. 0.)  1080\n",
      "sadness   (0. 0. 0. 1. 0. 0. 0.)  1079\n",
      "fear      (0. 1. 0. 0. 0. 0. 0.)  1078\n",
      "disgust   (0. 0. 0. 0. 1. 0. 0.)  1057\n",
      "guilt     (0. 0. 0. 0. 0. 0. 1.)  1057\n",
      "shame     (0. 0. 0. 0. 0. 1. 0.)  1045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lovedeep singh\\AppData\\Local\\Temp\\ipykernel_9404\\3243436489.py:108: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  joy=joy.resize((200,200),Image.ANTIALIAS)\n",
      "C:\\Users\\lovedeep singh\\AppData\\Local\\Temp\\ipykernel_9404\\3243436489.py:112: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  fear=fear.resize((200,200),Image.ANTIALIAS)\n",
      "C:\\Users\\lovedeep singh\\AppData\\Local\\Temp\\ipykernel_9404\\3243436489.py:116: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  anger=anger.resize((200,200),Image.ANTIALIAS)\n",
      "C:\\Users\\lovedeep singh\\AppData\\Local\\Temp\\ipykernel_9404\\3243436489.py:120: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  sadness=sadness.resize((200,200),Image.ANTIALIAS)\n",
      "C:\\Users\\lovedeep singh\\AppData\\Local\\Temp\\ipykernel_9404\\3243436489.py:124: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  disgust=disgust.resize((200,200),Image.ANTIALIAS)\n",
      "C:\\Users\\lovedeep singh\\AppData\\Local\\Temp\\ipykernel_9404\\3243436489.py:128: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  shame=shame.resize((200,200),Image.ANTIALIAS)\n",
      "C:\\Users\\lovedeep singh\\AppData\\Local\\Temp\\ipykernel_9404\\3243436489.py:132: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  guilt=guilt.resize((200,200),Image.ANTIALIAS)\n",
      "C:\\Users\\lovedeep singh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LinearSVC from version 0.24.1 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "sadness\n",
      "guilt\n",
      "fear\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle\n",
    "#import emoji\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import ImageTk ,Image\n",
    "\n",
    "root = Tk()\n",
    "w, h = root.winfo_screenwidth(), root.winfo_screenheight()\n",
    "root.geometry(\"%dx%d+0+0\" % (w, h))\n",
    "root.config(bg=\"powder blue\")\n",
    "root.title(\"Text Emotion\")\n",
    "\n",
    "ent_var=StringVar()\n",
    "\n",
    "global X_train, X_test\n",
    "\n",
    "def read_data():\n",
    "    data = []\n",
    "    with open('text_emotion.txt', 'r')as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
    "            text = line[line.find(\"]\")+1:].strip()\n",
    "            data.append([label, text])\n",
    "    return data\n",
    "data = read_data()\n",
    "print(\"Number of instances: {}\".format(len(data)))\n",
    "\n",
    "def ngram(token, n):\n",
    "    output = []\n",
    "    for i in range(n-1, len(token)):\n",
    "        ngram = ' '.join(token[i-n+1:i+1])\n",
    "        output.append(ngram)\n",
    "    return output\n",
    "def create_feature(text, nrange=(1, 1)):\n",
    "    text_features = []\n",
    "    text = text.lower()\n",
    "    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n",
    "    for n in range(nrange[0], nrange[1]+1):\n",
    "        text_features += ngram(text_alphanum.split(), n)\n",
    "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
    "    text_features += ngram(text_punc.split(), 1)\n",
    "    return Counter(text_features)\n",
    "\n",
    "\n",
    "def convert_label(item, name):\n",
    "    items = list(map(float, item.split()))\n",
    "    label = \"\"\n",
    "    for idx in range(len(items)):\n",
    "        if items[idx] == 1:\n",
    "            label += name[idx] + \" \"\n",
    "\n",
    "    return label.strip()\n",
    "\n",
    "emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "\n",
    "X_all = []\n",
    "y_all = []\n",
    "for label, text in data:\n",
    "    y_all.append(convert_label(label, emotions))\n",
    "    X_all.append(create_feature(text, nrange=(1, 4)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 15)\n",
    "\n",
    "def train_test(clf, X_train, y_train):\n",
    "    clf.fit(X_train, y_train)\n",
    "    filename=\"trained_model.sav\"\n",
    "    pickle.dump(clf, open(filename, \"wb\"))\n",
    "\n",
    "def text():\n",
    "    svc = SVC()\n",
    "    lsvc = LinearSVC(random_state=123)\n",
    "    rforest = RandomForestClassifier(random_state=123)\n",
    "    dtree = DecisionTreeClassifier()\n",
    "\n",
    "    clifs = [svc, lsvc, rforest, dtree]\n",
    "    # train and test them\n",
    "    print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
    "    print(\"| {} | {} | {} |\".format(\"-\" * 25, \"-\" * 17, \"-\" * 13))\n",
    "\n",
    "    for clf in clifs:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        full_train=train_test(clf, X_train,  y_train)\n",
    "        print(full_train)\n",
    "\n",
    "l = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "l.sort()\n",
    "print(l)\n",
    "label_freq = {}\n",
    "\n",
    "for label, _ in data:\n",
    "    label_freq[label] = label_freq.get(label, 0) + 1\n",
    "#print(label_freq)\n",
    "\n",
    "# print the labels and their counts in sorted order\n",
    "for l in sorted(label_freq, key=label_freq.get, reverse=True):\n",
    "    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))\n",
    "\n",
    "joy=Image.open(\"joy.png\")\n",
    "joy=joy.resize((200,200),Image.ANTIALIAS)\n",
    "joy=ImageTk.PhotoImage(joy)\n",
    "\n",
    "fear=Image.open(\"fear.png\")\n",
    "fear=fear.resize((200,200),Image.ANTIALIAS)\n",
    "fear=ImageTk.PhotoImage(fear)\n",
    "\n",
    "anger=Image.open(\"anger.png\")\n",
    "anger=anger.resize((200,200),Image.ANTIALIAS)\n",
    "anger=ImageTk.PhotoImage(anger)\n",
    "\n",
    "sadness=Image.open(\"sadeness.png\")\n",
    "sadness=sadness.resize((200,200),Image.ANTIALIAS)\n",
    "sadness=ImageTk.PhotoImage(sadness)\n",
    "\n",
    "disgust=Image.open(\"disgust.png\")\n",
    "disgust=disgust.resize((200,200),Image.ANTIALIAS)\n",
    "disgust=ImageTk.PhotoImage(disgust)\n",
    "\n",
    "shame=Image.open(\"shame.png\")\n",
    "shame=shame.resize((200,200),Image.ANTIALIAS)\n",
    "shame=ImageTk.PhotoImage(shame)\n",
    "\n",
    "guilt=Image.open(\"guilt.png\")\n",
    "guilt=guilt.resize((200,200),Image.ANTIALIAS)\n",
    "guilt=ImageTk.PhotoImage(guilt)\n",
    "\n",
    "emoji_dict = {\"joy\":joy, \"fear\":fear, \"anger\":PhotoImage(file = r\"anger.png\"), \"sadness\":PhotoImage(file = r\"sadeness.png\"), \"disgust\":PhotoImage(file = r\"disgust.png\"), \"shame\":PhotoImage(file = r\"shame.png\"), \"guilt\":PhotoImage(file = r\"guilt.png\")}\n",
    "\n",
    "\n",
    "\n",
    "t1 = \"This looks so impressive\"\n",
    "t2 = \"I have a fear of dogs\"\n",
    "t3 = \"My dog died yesterday\"\n",
    "t4 = \"I don't love you anymore..!\"\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse = True)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "def abcs():\n",
    "\n",
    "    features = create_feature(ent_var.get(), nrange=(1, 4))\n",
    "    features = vectorizer.transform(features)\n",
    "    model = pickle.load(open(\"trained_model.sav\", \"rb\"))\n",
    "    prediction = model.predict(features)[0]\n",
    "    print(prediction)\n",
    "    lbl2 = Label(root, image=emoji_dict[prediction])\n",
    "    lbl2.place(x=(w/5+w/4), y=(h/4+h/4), height=200, width=200)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in ent_var.get():\n",
    "    features = create_feature(i, nrange=(1, 4))\n",
    "    features = vectorizer.transform(features)\n",
    "    model=pickle.load(open(\"trained_model.sav\", \"rb\"))\n",
    "    prediction = model.predict(features)[0]\n",
    "    print(prediction)\n",
    "    lbl2 = Label(root, image=emoji_dict[prediction])\n",
    "    lbl2.place(x=0, y=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lbl=Label(root, text=\"Dectect Text Emotion\", bg=\"powder blue\", fg=\"blue\", font=(\"arial\", 20, \"bold\")).place(x=w/4, y=h/8, height=30, width=w/2)\n",
    "\n",
    "ent=Entry(root, fg=\"green\", textvariable=ent_var, font=(\"arial\", 20, \"bold italic\"))\n",
    "ent.place(x=w/4, y=h/5, height=30, width=w/2)\n",
    "\n",
    "btn=Button(root, text=\"Check Emotion\",  bg=\"sky blue\", fg=\"gray\", font=(\"arial\", 20, \"bold italic\"), command=abcs)\n",
    "btn.place(x=w/3, y=h/3, height=30, width=w/3)\n",
    "\n",
    "\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831b898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
